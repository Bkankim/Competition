{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYSJ/dYrrC7ihMF4sTNkN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bkankim/Competition/blob/main/Byeonghyeon_Competition_ML_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 준비 단계"
      ],
      "metadata": {
        "id": "G7CXrbZTPGeh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbRjmZOKEzza"
      },
      "outputs": [],
      "source": [
        "# 시각화 및 폰트 설정\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.font_manager as fm\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial import cKDTree\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import pickle\n",
        "import warnings;warnings.filterwarnings('ignore')\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "fe = fm.FontEntry(fname='/usr/share/fonts/truetype/nanum/NanumGothic.ttf', name='NanumBarunGothic')\n",
        "fm.fontManager.ttflist.insert(0, fe)\n",
        "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'})\n",
        "plt.rc('font', family='NanumBarunGothic')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 데이터 로드 및 결측치 처리"
      ],
      "metadata": {
        "id": "L_Gs6QIhPPYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정\n",
        "train_path = '/data/ephemeral/home/Bkan/Competition_dataset/train.csv'\n",
        "test_path = '/data/ephemeral/home/Bkan/Competition_dataset/test.csv'\n",
        "\n",
        "# 데이터 로딩\n",
        "train = pd.read_csv(train_path)\n",
        "test = pd.read_csv(test_path)\n",
        "\n",
        "# 테스트셋 구분 컬럼 추가\n",
        "train['is_test'] = 0\n",
        "test['is_test'] = 1\n",
        "\n",
        "# 전처리를 위한 통합 데이터 생성\n",
        "concat = pd.concat([train, test], axis=0)"
      ],
      "metadata": {
        "id": "_OOOfOcCL2nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 100만개 이상 결측된 컬럼 목록\n",
        "threshold = 1_000_000\n",
        "cols_to_drop = missing[missing >= threshold].index.tolist()\n",
        "# 삭제\n",
        "cols_to_drop"
      ],
      "metadata": {
        "id": "aQMir53cMAG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 남은 변수 분리\n",
        "continuous_cols = []\n",
        "categorical_cols = []\n",
        "\n",
        "for col in concat.columns:\n",
        "    if pd.api.types.is_numeric_dtype(concat[col]):\n",
        "        continuous_cols.append(col)\n",
        "    else:\n",
        "        categorical_cols.append(col)\n",
        "\n",
        "# 특수처리: 숫자지만 범주형인 '본번', '부번'\n",
        "for col in ['본번', '부번']:\n",
        "    if col in continuous_cols:\n",
        "        concat[col] = concat[col].astype(str)\n",
        "        continuous_cols.remove(col)\n",
        "        categorical_cols.append(col)\n",
        "\n",
        "# 결측치 채움\n",
        "concat[categorical_cols] = concat[categorical_cols].fillna('NULL')\n",
        "concat[continuous_cols] = concat[continuous_cols].interpolate(method='linear', axis=0)"
      ],
      "metadata": {
        "id": "yurS_xfPMD5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치는 아닌데 의미 없는 형식적 값 찾기\n",
        "def detect_fake_nulls(df, suspect_values=['-', ' ', '', '.', '없음', 'nan']):\n",
        "    result = {}\n",
        "    for col in df.columns:\n",
        "        if concat[col].dtype == 'object':\n",
        "            val_counts = concat[col].value_counts(dropna=False)\n",
        "            found = val_counts[val_counts.index.isin(suspect_values)]\n",
        "            if not found.empty:\n",
        "                result[col] = found\n",
        "    return result\n",
        "\n",
        "fake_nulls = detect_fake_nulls(concat)"
      ],
      "metadata": {
        "id": "Vcfw_Rf4MJbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 의미 없는 값 정의\n",
        "fake_null_values = ['-', ' ', '', '.', '없음', 'nan']\n",
        "\n",
        "# 문자형 컬럼 기준 일괄 변환\n",
        "object_cols = concat.select_dtypes(include='object').columns.tolist()\n",
        "for col in object_cols:\n",
        "    concat[col] = concat[col].replace(fake_null_values, np.nan)"
      ],
      "metadata": {
        "id": "FL4IT8lTMLzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 복사본 생성\n",
        "concat_select = concat.copy()\n",
        "\n",
        "# 본번, 부번 → 문자형 변환\n",
        "concat_select['본번'] = concat_select['본번'].astype(str)\n",
        "concat_select['부번'] = concat_select['부번'].astype(str)\n",
        "\n",
        "# 연속형 변수 추출\n",
        "continuous_cols = concat_select.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "continuous_cols = [col for col in continuous_cols if col != 'is_test']  # is_test 제외\n",
        "\n",
        "# 범주형 변수 추출\n",
        "categorical_cols = concat_select.select_dtypes(include=['object']).columns.tolist()"
      ],
      "metadata": {
        "id": "E4psosaOMPwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 수치형 변수 목록\n",
        "train_only = concat[concat['is_test'] == 0].copy()\n",
        "numeric_cols = train_only.select_dtypes(include=np.number).columns.tolist()\n",
        "numeric_cols = [col for col in numeric_cols if col not in ['is_test']]\n",
        "\n",
        "# 결측치 비율 계산\n",
        "missing_ratio = train_only[numeric_cols].isnull().mean()\n",
        "\n",
        "# 상관계수 계산\n",
        "corr_matrix = train_only[numeric_cols].corr()\n",
        "target_corr = corr_matrix['target'].drop('target')\n",
        "\n",
        "# 결측비율 + 상관계수 조합 테이블\n",
        "value_check = pd.DataFrame({\n",
        "    '결측비율': missing_ratio,\n",
        "    'target_상관계수': target_corr,\n",
        "    '절대_상관': target_corr.abs()\n",
        "}).sort_values(by='절대_상관', ascending=False)"
      ],
      "metadata": {
        "id": "imwkxS-kMUpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수치형 변수 필터링\n",
        "train_only = concat[concat['is_test'] == 0].copy()\n",
        "numeric_cols = train_only.select_dtypes(include=np.number).columns.tolist()\n",
        "numeric_cols = [col for col in numeric_cols if col not in ['is_test']]\n",
        "\n",
        "# 상관계수 계산\n",
        "corr = train_only[numeric_cols].corr()"
      ],
      "metadata": {
        "id": "LolOjTX3Mhxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 이상치 처리\n",
        "> 클리핑, 로그변환"
      ],
      "metadata": {
        "id": "YL6_QvktQExb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 전용면적 이상치 클리핑 셀\n",
        "# 복사본 생성\n",
        "concat['전용면적_clip'] = concat['전용면적(㎡)'].copy()\n",
        "\n",
        "# 상하위 0.5% 경계 계산\n",
        "q_low = concat['전용면적_clip'].quantile(0.005)\n",
        "q_high = concat['전용면적_clip'].quantile(0.995)\n",
        "\n",
        "# 클리핑 적용\n",
        "concat['전용면적_clip'] = concat['전용면적_clip'].clip(lower=q_low, upper=q_high)"
      ],
      "metadata": {
        "id": "5ocr7Fx8Mn2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## k-주거전용면적과 k-전체세대수 사이에 상관관계가 있는지 확인\n",
        "# # 세대당 전용면적 파생 변수 생성\n",
        "concat['세대당_전용면적'] = concat['k-주거전용면적'] / concat['k-전체세대수']\n",
        "\n",
        "## lgbm을 사용할 거기 때문에 로그스케일대신 클리핑을 채택\n",
        "# 하위/상위 0.5% 경계 계산\n",
        "low = concat['세대당_전용면적'].quantile(0.005)\n",
        "high = concat['세대당_전용면적'].quantile(0.995)\n",
        "\n",
        "# 클리핑 적용\n",
        "concat['세대당_전용면적_clip'] = concat['세대당_전용면적'].clip(lower=low, upper=high)"
      ],
      "metadata": {
        "id": "GwU-XYhVMskV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 각별한 이상치가 없으므로 로그 변환 채택\n",
        "# 로그 변환\n",
        "concat['주차대수_log'] = np.log1p(concat['주차대수'])"
      ],
      "metadata": {
        "id": "JHephj7_M0Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 클리핑 분포도 이쁜편이고, 상관계수도 훨씬 높기때문에, 클리핑으로 채택\n",
        "# 클리핑 경계 설정\n",
        "lower = concat['k-연면적'].quantile(0.005)\n",
        "upper = concat['k-연면적'].quantile(0.995)\n",
        "\n",
        "# 클리핑 적용\n",
        "concat['k-연면적_clipped'] = concat['k-연면적'].clip(lower=lower, upper=upper)"
      ],
      "metadata": {
        "id": "z3-3WKmQNEo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 분포가 이쁘진 않지만 로그 변환으로 해석을 어렵게 할 필요는 없어보이므로 이것도 클리핑\n",
        "# 기본 통계 및 결측/상관 정보\n",
        "col = 'k-주거전용면적'\n",
        "\n",
        "# 클리핑 경계 계산 (0.5% ~ 99.5%)\n",
        "low, high = np.percentile(concat['k-주거전용면적'], [0.5, 99.5])\n",
        "\n",
        "# 클리핑 적용\n",
        "concat['k-주거전용면적_clipped'] = concat['k-주거전용면적'].clip(lower=low, upper=high)"
      ],
      "metadata": {
        "id": "VvjJGtiINJ2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concat에서 만든 파생변수들을 concat_select에 모두 복사\n",
        "concat_select['전용면적_clip'] = concat['전용면적_clip']\n",
        "concat_select['세대당_전용면적'] = concat['세대당_전용면적']\n",
        "concat_select['세대당_전용면적_clip'] = concat['세대당_전용면적_clip']\n",
        "concat_select['주차대수_log'] = concat['주차대수_log']\n",
        "concat_select['k-연면적_log'] = concat['k-연면적_log']\n",
        "concat_select['k-연면적_clipped'] = concat['k-연면적_clipped']\n",
        "concat_select['k-주거전용면적_clipped'] = concat['k-주거전용면적_clipped']"
      ],
      "metadata": {
        "id": "Yb4A1y3JNRlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 도메인 기반 사고 & 결측치도 동반하기 때문에 필요없다 판단하여 삭제\n",
        "rop_cols = ['등기신청일자', '중개사소재지', '거래유형', '도로명', 'k-시행사']\n",
        "concat_select = concat_select.drop(columns=drop_cols)"
      ],
      "metadata": {
        "id": "giuCtmsUNauy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼 동기화 (드롭된 컬럼 제거)\n",
        "categorical_cols = [col for col in categorical_cols if col in concat_select.columns]\n",
        "continuous_cols = [col for col in continuous_cols if col in concat_select.columns]"
      ],
      "metadata": {
        "id": "4wYrBEamNlK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 파생 변수 생성\n",
        "> 따릉이, 지하철역 거리\n",
        ">\n",
        "> KDTree : 브루트포스보다 훨씬 빠른 처리 및 아파트와의 직선거리 계산"
      ],
      "metadata": {
        "id": "3_ul0YgQQS3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시군구, 년월 등 분할할 수 있는 변수들은 세부사항 고려를 용이하게 하기 위해 모두 분할해 주겠습니다.\n",
        "concat_select['구'] = concat_select['시군구'].map(lambda x : x.split()[1])\n",
        "concat_select['동'] = concat_select['시군구'].map(lambda x : x.split()[2])\n",
        "del concat_select['시군구']\n",
        "\n",
        "concat_select['계약년'] = concat_select['계약년월'].astype('str').map(lambda x : x[:4])\n",
        "concat_select['계약월'] = concat_select['계약년월'].astype('str').map(lambda x : x[4:])\n",
        "del concat_select['계약년월']"
      ],
      "metadata": {
        "id": "DHZA7NiKNoD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 강남의 여부를 체크합니다.\n",
        "is_gangnam = []\n",
        "for x in concat_select['구'].tolist() :\n",
        "  if x in gangnam :\n",
        "    is_gangnam.append(1)\n",
        "  else :\n",
        "    is_gangnam.append(0)\n",
        "\n",
        "# 파생변수를 하나 만릅니다.\n",
        "concat_select['강남여부'] = is_gangnam"
      ],
      "metadata": {
        "id": "MbBmAiCnOJyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 베이스코드 feature importance와 내 도메인 지식을 기반으로 제거할 컬럼을 정해 제거함.\n",
        "drop_indices = [8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 21, 26, 27, 28, 29, 32, 33, 34, 35, 38]\n",
        "drop_cols = [concat_select.columns[i] for i in drop_indices]\n",
        "concat_select.drop(columns=drop_cols, inplace=True)"
      ],
      "metadata": {
        "id": "fji-cPOPOPDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 외부 파일 불러오기\n",
        "subway = pd.read_csv('/data/ephemeral/home/Bkan/Competition_dataset/subway_feature.csv')  # 지하철역 위경도 데이터\n",
        "bike = pd.read_csv('/data/ephemeral/home/Bkan/Competition_dataset/bike_station.csv', encoding='cp949')      # 따릉이 대여소 위경도 데이터"
      ],
      "metadata": {
        "id": "eBa-LqX8Ob_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 아파트 기준 좌표 (위도, 경도)\n",
        "apt_coords = np.vstack([concat_select['좌표Y'], concat_select['좌표X']]).T\n",
        "\n",
        "# 지하철 좌표\n",
        "subway_coords = np.vstack([subway['위도'], subway['경도']]).T\n",
        "subway_tree = cKDTree(subway_coords)\n",
        "\n",
        "# 따릉이 좌표 (결측/0.0 제거)\n",
        "bike_clean = bike[(bike['위도'] > 0) & (bike['경도'] > 0)].copy()\n",
        "bike_coords = np.vstack([bike_clean['위도'], bike_clean['경도']]).T\n",
        "bike_tree = cKDTree(bike_coords)"
      ],
      "metadata": {
        "id": "cP9UTnYVOlH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KDTree를 위한 기준 좌표 준비\n",
        "apt_coords = np.vstack([concat_select['좌표Y'], concat_select['좌표X']]).T\n",
        "\n",
        "# 지하철 KDTree\n",
        "subway_coords = np.vstack([subway['위도'], subway['경도']]).T\n",
        "subway_tree = cKDTree(subway_coords)\n",
        "\n",
        "# 따릉이 KDTree (0.0 또는 NaN 제거)\n",
        "bike_clean = bike[(bike['위도'] > 0) & (bike['경도'] > 0)]\n",
        "bike_coords = np.vstack([bike_clean['위도'], bike_clean['경도']]).T\n",
        "bike_tree = cKDTree(bike_coords)\n",
        "\n",
        "# 최단거리\n",
        "concat_select['지하철_최단거리'] = subway_tree.query(apt_coords)[0]\n",
        "concat_select['따릉이_최단거리'] = bike_tree.query(apt_coords)[0]\n",
        "\n",
        "# 반경 내 지하철역 개수 (500m ≈ 0.005도)\n",
        "subway_counts = subway_tree.query_ball_point(apt_coords, r=0.005)\n",
        "concat_select['지하철_500m내_개수'] = [len(x) for x in subway_counts]\n",
        "\n",
        "# 반경 내 따릉이 대여소 개수 (300m ≈ 0.003도)\n",
        "bike_counts = bike_tree.query_ball_point(apt_coords, r=0.003)\n",
        "concat_select['따릉이_300m내_개수'] = [len(x) for x in bike_counts]"
      ],
      "metadata": {
        "id": "oDK-nWDhOoTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 분포가 오른쪽 긴꼬리 양상을 보이기 때문에 로그 변환 실행\n",
        "# 로그 변환 적용\n",
        "concat_select['지하철_최단거리_log'] = np.log1p(concat_select['지하철_최단거리'])\n",
        "concat_select['따릉이_최단거리_log'] = np.log1p(concat_select['따릉이_최단거리'])"
      ],
      "metadata": {
        "id": "JcLPo0L8Ou4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 모델 정의 및 학습 실행\n",
        "> LightGBM 채택\n",
        ">\n",
        "> 1. 속도 : RF 대비 10배 빠른 처리 속도\n",
        ">\n",
        "> 2. 도메인 적합성 : 부동산의 복잡한 비선형성에 최적\n",
        ">\n",
        "> 3. 성능 : 95% 이상 향상 (실제 대회 결과)"
      ],
      "metadata": {
        "id": "9vwVg66iQcTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용과 테스트용 분리\n",
        "df = concat_select.copy()\n",
        "train_df = df[df['is_test'] == 0]\n",
        "X = train_df.drop(columns=['target', 'is_test'])\n",
        "y = train_df['target']\n",
        "\n",
        "# 학습 / 검증셋 분할\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "UFqvwRdnOy8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lgbm은 한글 변수를 학습하지 못하기 때문에 인코딩 작업\n",
        "cat_cols_to_encode = [\n",
        "    '번지', '본번', '부번', '아파트명',\n",
        "    'k-난방방식', 'k-수정일자',\n",
        "    '구', '동', '계약년', '계약월'\n",
        "]\n",
        "\n",
        "# 전체 데이터(train + test)를 사용하여 LabelEncoder 학습\n",
        "label_encoders = {}\n",
        "for col in cat_cols_to_encode:\n",
        "    le = LabelEncoder()\n",
        "    # 전체 데이터를 사용하여 fit (train + test 모두 포함)\n",
        "    le.fit(df[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "    # train과 valid에 transform 적용\n",
        "    X_train[col] = le.transform(X_train[col].astype(str))\n",
        "    X_valid[col] = le.transform(X_valid[col].astype(str))"
      ],
      "metadata": {
        "id": "1tKDFWuyOyyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 변환\n",
        "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
        "lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train, free_raw_data=False)\n",
        "\n",
        "# 하이퍼파라미터 기본값\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,  # 기본값\n",
        "    'learning_rate': 0.05,  # 기본값\n",
        "    'feature_fraction': 0.9,  # 약간만 조정\n",
        "    'verbosity': -1,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "# 학습 실행\n",
        "model = lgb.train(\n",
        "    params,\n",
        "    lgb_train,\n",
        "    valid_sets=[lgb_train, lgb_valid],\n",
        "    num_boost_round=4000,\n",
        "    callbacks=[\n",
        "        early_stopping(100),\n",
        "        log_evaluation(100)  # 100번째마다 로그 출력\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "lV5h28tMOyu7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}